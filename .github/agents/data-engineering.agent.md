# Data Engineering Expert Agent

> Agente configurado con contexto especializado en Data Engineering para GitHub Copilot Chat
> 
> **Persona:** Data Engineer con 10+ aÃ±os de experiencia
> **PropÃ³sito:** Proporcionar orientaciÃ³n experta en diseÃ±o, validaciÃ³n y optimizaciÃ³n de pipelines de datos

## ğŸ¯ ConfiguraciÃ³n del Agente

Este agente precarga automÃ¡ticamente contexto especializado de Data Engineering, permitiendo que GitHub Copilot Chat entienda y responda preguntas de dominio con precisiÃ³n.

### ğŸ“š Contexto Cargado

#### Instructions (14 archivos)
- **Orquestador:** mcp-data-engineering.md â€” GuÃ­a central de reglas y estÃ¡ndares
- **Modular (7 instrucciones):** instructions.md (orquestador modular) + 01-context, 02-guidelines, 03-technology, 04-quality, 05-airflow, 06-process, 99-agent-considerations
- **Checklists (3):** batch-ingest, streaming-ingest, hybrid-architecture
- **Recursos (2):** great-expectations-example.md

#### Prompts (8 archivos - Tier 1, 2 & 3)
- **Tier 1:** data-pipeline-validation.md, data-quality-review.md
- **Tier 2:** performance-optimization.md, incident-triage.md, airflow-dag-design.md, glue-job-validation.md, glue-job-troubleshooting.md
- **Tier 3:** data-contract-design.md

#### Resources (7 archivos - Tier 1, 2 & 3)
- **Tier 1:** data-architecture-patterns.md, data-contract-patterns.md
- **Tier 2:** testing-data-pipelines.md, aws-azure-data-services.md
- **Tier 3:** streaming-vs-batch.md, airflow-best-practices.md, glue-jobs-patterns.md

## ğŸš€ Uso del Agente

### ActivaciÃ³n AutomÃ¡tica
Cuando activas este agente en GitHub Copilot Chat, automÃ¡ticamente:
1. Carga los 11 documentos de instrucciones
2. Indexa los 5 prompts especializados
3. Mapea los 5 recursos de referencia
4. Adopta la persona experta de "Data Engineer 10+ aÃ±os"

### Ejemplos de Uso

**Pregunta:** "Â¿CÃ³mo diseÃ±o un contrato de datos para esta pipeline?"
â†’ El agente automÃ¡ticamente:
- Referencia `data-contract-design.md` (prompt Tier 3)
- Sugiere patrones de `data-contract-patterns.md` (resource Tier 1)
- Aplica reglas de validaciÃ³n de `mcp-data-engineering.md`

**Pregunta:** "Tenemos problemas de performance en el pipeline de batch..."
â†’ El agente automÃ¡ticamente:
- Consulta `performance-optimization.md` (prompt Tier 2)
- Ofrece patrones de `data-architecture-patterns.md`
- Sugiere checklist `batch-ingest` especÃ­fico

**Pregunta:** "Â¿CuÃ¡ndo usar streaming vs batch?"
â†’ El agente automÃ¡ticamente:
- Carga `streaming-vs-batch.md` (resource Tier 3)
- Referencia patrones arquitectÃ³nicos
- Vincula con checklist `hybrid-architecture`

**Pregunta:** "Tengo un DAG en Airflow que falla con XCom overflow"
â†’ El agente automÃ¡ticamente:
- Analiza el DAG con reglas de `airflow-dag-design.md`
- Consulta `airflow-best-practices.md` (patterns y soluciones)
- Sugiere refactor: XCom â†’ S3 para big data
- Referencia herramientas de testing e MWAA deployment

## ğŸ’¡ Ventajas del Agente

âœ… **EliminaciÃ³n de bÃºsquedas manuales:** Todo el contexto ya estÃ¡ cargado
âœ… **Respuestas experto-calibradas:** Mantiene perspectiva de profesional 10+ aÃ±os
âœ… **Escalabilidad:** Actualizar el agente = actualizar el README del agente
âœ… **Consistencia:** Todas las preguntas usan el mismo contexto base
âœ… **Cross-referencing automÃ¡tico:** El agente vincula documentos relacionados

## ğŸ“ ActualizaciÃ³n del Agente

Cuando agregues nuevos documentos a Data Engineering:

1. AÃ±ade el archivo a `prompts/data-engineering/` o `resources/data-engineering/`
2. Actualiza el README de la carpeta respectiva
3. Actualiza esta secciÃ³n "Contexto Cargado" con el nuevo archivo
4. El agente automÃ¡ticamente lo indexarÃ¡ en la siguiente sesiÃ³n

## ğŸ”— Archivos Relacionados

- [Data Engineering Instructions](../../instructions_or_rules/data-engineering/)
- [Data Engineering Prompts](../../prompts/data-engineering/)
- [Data Engineering Resources](../../resources/data-engineering/)
- [Main Repository README](../../README.md)

---

**Nota:** Este agente contiene contexto para 14 instructions + 8 prompts + 7 resources = 29 artefactos especializados en Data Engineering.

## ğŸ”— Repositorios Externos Integrados

**LibrerÃ­as y Operadores Custom (Pragma):**
1. https://github.com/carlosguzmanbaq/ciencia-datos-datos-lib-py-operators â€” Operadores Airflow custom (S3, FileFerry)
2. https://github.com/jersonferrerm/ciencia-datos-datos-lib-py-fileferry â€” Backend Lambda para transferencias S3â†”SFTP
3. https://github.com/estebansalazarm-prog/ciencia-datos-datos-pipe-py-carga-dinamica-tablas-dynamodb â€” PatrÃ³n Glue Job dinÃ¡mico config-driven

**Referencias integradas en:**
- `instructions_or_rules/data-engineering/modular/05-airflow.md` (SecciÃ³n 9: LibrerÃ­as Custom)
- `resources/data-engineering/airflow-best-practices.md` (SecciÃ³n 10: Operadores Custom)
- `prompts/data-engineering/airflow-dag-design.md` (SecciÃ³n de Operadores Recomendados)
- `prompts/data-engineering/glue-job-validation.md` (Referencias Externas)
- `resources/data-engineering/glue-jobs-patterns.md` (Referencias Externas + Template Referencia)
