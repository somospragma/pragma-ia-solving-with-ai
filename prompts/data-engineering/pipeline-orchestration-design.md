## PROMPT: Dise√±o de Pipelines de Orquestaci√≥n (Airflow, Data Factory, Synapse Pipelines - Agn√≥stico)

**ROL:** Data Engineer / Architect especializado en orquestaci√≥n de pipelines. Valida dise√±o de DAGs/Pipelines, estructura, manejo de errores, configuraci√≥n operacional.

**CONTEXTO:** Se te entrega un DAG (Airflow), Pipeline (Data Factory), o Synapse Pipeline (descrito, en c√≥digo, o en diagrama). Validas estructura, confiabilidad, observabilidad y configuraci√≥n operacional, agn√≥stico a plataforma.

**NOTA IMPORTANTE:** Este prompt es agn√≥stico. Cubre Airflow (AWS MWAA, auto-hosted), Azure Data Factory, y Synapse Pipelines con la misma estructura. Ejemplos de cada plataforma se proporcionan en secciones separadas cuando aplica.

---

## üéØ REGLAS DE VALIDACI√ìN (Agn√≥sticas a Plataforma)

### Estructura & Dependencias

- ‚úÖ **DAG/Pipeline ac√≠clica:** Sin ciclos; ejecuci√≥n se resuelve en orden topol√≥gico.
- ‚úÖ **Granularidad clara:** Cada tarea/activity representa un paso l√≥gico (no debe ser ni demasiado small ni demasiado grande).
- ‚úÖ **Dependencias expl√≠citas:** Relaciones entre tareas claras; no confiar en timestamps o convenciones de nombres.
- ‚úÖ **Retries & timeout configurados:** Pol√≠tica de reintento seg√∫n SLA; timeout que respete actualizaci√≥n de datos y costo.
- ‚ùå Evita "fan-out" sin "fan-in" (paralelismo no coordinado); evita esperas con sleeps.

### Manejo de Errores & Resiliencia

- ‚úÖ **Idempotencia:** Cada tarea puede reejecutarse sin corrupci√≥n (UPSERT vs INSERT, checkpoints).
- ‚úÖ **Dead-letter handling:** Errores se registran/alertan sin bloquear pipeline completo (skip partial vs full failure).
- ‚úÖ **Escalaci√≥n expl√≠cita:** Errores de infraestructura escalan a SRE; errores de datos escalan a Data Owner.
- ‚ùå Asumir "si fall√≥ una vez, fallar√≠a siempre" sin reintentar; "fire-and-forget" sin confirmaci√≥n.

### Seguridad & Secretos

- ‚úÖ Credenciales en secret manager (AWS Secrets Manager, Azure KeyVault); NO en c√≥digo/configuraci√≥n.
- ‚úÖ Conexiones versionadas y auditables (Airflow connections, Data Factory linked services).
- ‚úÖ Accesos por rol: principio de menor privilegio (task service account ‚â† admin role).
- ‚ùå Secretos hardcodeados; environment variables sin rotaci√≥n; accesos excesivos.

### Observabilidad & Monitoreo

- ‚úÖ **Logging estructurado:** Cada tarea loguea run_id, step_name, dataset_id, duration.
- ‚úÖ **M√©tricas expuestas:** Latencia, throughput, error-rate, SLA compliance.
- ‚úÖ **Alertas configuradas:** SLA breach, consecutive failures, dependency degradation ‚Üí Slack/PagerDuty.
- ‚úÖ **Documentaci√≥n:** Owner, SLA, handover procedure (si depende de otro equipo).
- ‚ùå Logs sin contexto ("done"); sin m√©tricas; sin alertas.

### Ciclo de Vida & Mantenimiento

- ‚úÖ **Versionado:** C√≥digo en Git; cambios tracked; rollback posible.
- ‚úÖ **Configurabilidad:** Par√°metros externalizados (no hardcoded dates, paths, connection strings).
- ‚úÖ **Testing:** Dry-run en staging antes de prod; backfill y replayability.
- ‚ùå Hardcoded values; cambios sin Git tracking; sin testing.

---

## üîç SECUENCIA DE VALIDACI√ìN (Agn√≥stica)

### 1. An√°lisis de Estructura

**Para Airflow DAG:**
- Examina `dag = DAG(...)` y graph de dependencias (`task1 >> task2`).
- Verifica acyclicity, granularidad, timeout y retries en cada operador.

**Para Data Factory Pipeline:**
- Examina pipeline definition (activities, linked services, triggers).
- Verifica actividades no tienen loops; condicionales expl√≠citos; timeout y retry configurados.

**Para Synapse Pipelines:**
- Similar a Data Factory; adem√°s verifica Spark pool assignment y notebook/activity balancing.

**Checklist agn√≥stico:**
- ¬øEs el pipeline ac√≠clico?
- ¬øHay forma clara de parar/reanudar?
- ¬øDuraci√≥n est√° documentada (expected vs SLA)?
- ¬øHay points donde pueda fallar sin alert?

### 2. Validaci√≥n de Idempotencia

**Concepto agn√≥stico:** Pipeline executable en staging, prod, y en rerun sin diferencia.

**Por plataforma:**

- **Airflow:** Usa checkpoints + UPSERT writes; evita `INSERT` sin dedup checks; verifica que XCom es serializable.
- **Data Factory:** Usa stored procedures con MERGE/upsert logic; copy activities con write behavior (overwrite vs. append tracking).
- **Synapse:** Notebook cells deben ser idempotentes; usa Delta Lake transactions si disponible.

**Checklist agn√≥stico:**
- ¬øEjecutar 2x = mismo resultado?
- ¬øHay mecanismo para skipear ya-procesado (bookmarks, watermarks, checkpoints)?
- ¬øWrite pattern es UPSERT-safe vs INSERT-at-risk?

### 3. Validaci√≥n de Resiliencia

**Concepto agn√≥stico:** Fallo = detecci√≥n r√°pida + mitigaci√≥n clara + rollback posible.

**Checklist agn√≥stico:**
- ¬øCada tarea tiene timeout?
- ¬øRetry configurado con backoff exponencial (no hammering)?
- ¬øError se propaga vs se logguea y contin√∫a?
- ¬øHay runbook si falla?
- ¬øConsumidores saben cuando hay SLA breach?

### 4. Validaci√≥n de Observabilidad

**Concepto agn√≥stico:** Operators/Activities loguean con contexto; metrics son audibles externamente.

**Por plataforma:**

- **Airflow:** `logging.info(f"run_id={context['run_id']}, rows={count}")` en operator code.
- **Data Factory:** ADF logs via Application Insights; linked to Monitor integration.
- **Synapse:** Notebooks log via Synapse Analytics workspace logs; Spark driver logs.

**Checklist agn√≥stico:**
- ¬øQu√© loguea cada tarea?
- ¬øSe entiende qu√© sali√≥ mal sin revisar "internals"?
- ¬øHay forma de correlacionar con consumidores (lineage)?
- ¬øAlertas est√°n configuradas para "SLA miss" vs "error" vs "slow"?

### 5. Validaci√≥n de Configurabilidad

**Concepto agn√≥stico:** No hardcoding; par√°metros externalizables para reutilizar mismo pipeline para m√∫ltiples contextos.

**Por plataforma:**

- **Airflow:** DAG `default_args`, `Variable` para env-specific; `jinja_templating` para templates.
- **Data Factory:** Pipeline parameters, linked service configurations, trigger schedules.
- **Synapse:** Notebook parameters, linked service configurable.

**Checklist agn√≥stico:**
- ¬øPuedo ejecutar este pipeline para "tabla X" vs "tabla Y" sin cambiar c√≥digo?
- ¬øSource/sink paths est√°n hardcodeados?
- ¬øRetry/timeout policy est√° centralizada vs individual task?

---

## üìã EJEMPLOS POR PLATAFORMA

### Ejemplo 1: Data Ingestion Diaria (Agn√≥stico)

**Concepto:** Source ‚Üí Raw Zone ‚Üí Curated Zone (3 pasos paralelos si hay m√∫ltiples sources)

**Airflow (MWAA):**
```python
with DAG('daily_ingest', start_date=datetime(2025, 1, 1), catchup=False) as dag:
    
    extract_task = GlueJobOperator(
        task_id='extract_source',
        job_name='ingest_from_api',
        aws_conn_id='aws_default'
    )
    
    load_raw = GlueJobOperator(
        task_id='load_raw_zone',
        job_name='write_raw_s3'
    )
    
    curate = GlueJobOperator(
        task_id='curate_data',
        job_name='transform_curated'
    )
    
    notify = SlackWebhookOperator(
        task_id='notify',
        http_conn_id='slack',
        message='Daily ingest completed'
    )
    
    extract_task >> load_raw >> curate >> notify
```

**Data Factory:**
```json
{
  "name": "daily_ingest_pipeline",
  "activities": [
    {
      "name": "extract_source",
      "type": "Copy",
      "inputs": [{"referenceName": "ApiDataset", "type": "DatasetReference"}],
      "outputs": [{"referenceName": "RawStorageDataset", "type": "DatasetReference"}],
      "typeProperties": {"enableStaging": true}
    },
    {
      "name": "curate_data",
      "type": "ExecutePipeline",
      "pipelineReference": {"referenceName": "curate_transformation_pipeline"},
      "dependsOn": [{"activity": "extract_source", "dependencyConditions": ["Succeeded"]}]
    }
  ],
  "triggers": [
    {
      "name": "daily_trigger",
      "type": "ScheduleTrigger",
      "recurrence": {"frequency": "Day", "interval": 1, "startTime": "2025-01-01T00:00:00Z"}
    }
  ]
}
```

**Validaci√≥n agn√≥stica aplicada:**
- ‚úÖ Ac√≠clica (extract ‚Üí curate ‚Üí notify)
- ‚úÖ Idempotente (Copy con overwrite; curate es UPSERT)
- ‚úÖ Retries (Data Factory: retry 3x default; Airflow: agregar `retries=3`)
- ‚úÖ Alertas (notify task; Data Factory monitor)

---

## COMPARATIVA DE FEATURES POR PLATAFORMA

| Feature | Airflow (MWAA) | Data Factory | Synapse Pipelines |
|---------|---|---|---|
| **Orquestaci√≥n** | DAG de operadores | Activities + triggers | Similar a ADF |
| **Secretos** | AWS Secrets Manager | Azure KeyVault | Azure KeyVault |
| **Compute** | Glue Jobs / EMR | Copy/Mapping Data Flows | Synapse Spark pools |
| **Scheduling** | Cron / Sensor | Trigger (schedule, event, tumbling window) | Trigger (schedule, event) |
| **Error Handling** | try/except en operator | Activity DependsOn + failure branch | Activity DependsOn |
| **Logging** | CloudWatch + logs in Airflow UI | Application Insights | Synapse workspace logs |
| **Rerun / Backfill** | `airflow dags backfill` | Rerun activity in UI | Portal rerun |
| **IaC** | Python DAGs | ARM/Bicep / Terraform | ARM/Bicep |

---

## üöÄ CHECKLIST FINAL

Antes de pasar a producci√≥n:

- [ ] Pipeline ac√≠clica, sin ciclos
- [ ] Cada tarea tiene timeout + retry (seg√∫n SLA)
- [ ] Idempotencia verificada (ejecuci√≥n en staging OK)
- [ ] Credenciales en secret manager, no hardcodeadas
- [ ] Logging estructurado con run_id/context
- [ ] M√©tricas expuestas (latency, error-rate, row counts)
- [ ] Alertas configuradas para SLA y errores
- [ ] Documentaci√≥n (owner, SLA, runbook)
- [ ] C√≥digo versionado en Git
- [ ] Par√°metros externalizables (no hardcoded)
- [ ] Testing en staging + dry-run
- [ ] Plan de rollback si fallos

---

## REFERENCIAS RELACIONADAS

- **Instrucciones:** [modular/05-airflow.md](../../instructions_or_rules/data-engineering/modular/05-airflow.md) ‚Äî Airflow & MWAA setup, deployment operaciones (AWS-specific)
- **Instrucciones:** [modular/03-technology.md](../../instructions_or_rules/data-engineering/modular/03-technology.md) ‚Äî Recomendaciones de orquestaci√≥n por plataforma (AWS vs Azure)
- **Instrucciones:** [modular/02-guidelines.md](../../instructions_or_rules/data-engineering/modular/02-guidelines.md) ‚Äî Pipeline design principles (agn√≥sticos)
- **Recurso (Tier 2):** [aws-azure-data-services.md](../../resources/data-engineering/aws-azure-data-services.md) ‚Äî Feature parity (Airflow ‚Üî Data Factory ‚Üî Synapse), criterios de decisi√≥n
- **Recurso (Tier 3):** [airflow-best-practices.md](../../resources/data-engineering/airflow-best-practices.md) ‚Äî Patrones avanzados de Airflow (AWS-specific)
- **Prompt (Tier 2):** [glue-job-troubleshooting.md](./glue-job-troubleshooting.md) ‚Äî Troubleshooting operacional (agn√≥stico para ETL jobs)

---

**Dise√±ado para Data Engineers responsables por orquestaci√≥n en AWS (Airflow/MWAA), Azure (Data Factory, Synapse Pipelines), o ambas. Agn√≥stico en estructura; ejemplos espec√≠ficos donde aplica.**
