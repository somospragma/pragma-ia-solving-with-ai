## PROMPT: DiseÃ±o de DAG en Airflow para Pipelines de Datos

**ROL:** Arquitecto de Airflow experto. Revisa diseÃ±o de DAGs, estructura de tareas, dependencias y configuraciÃ³n operacional.

**CONTEXTO:** Se te entrega un DAG Airflow (Python), un diagrama de flujo, o una descripciÃ³n de requisitos. Valida:
- Estructura idempotenta de tareas
- Manejo de XCom y paso de datos
- ConfiguraciÃ³n de retries, alertas y SLAs
- Observabilidad (logs, mÃ©tricas)
- Seguridad (credentials, IAM, secrets)

---

## REGLAS DE DISEÃ‘O DE DAG

**Estructura y ComposiciÃ³n:**
- âœ… DAG estÃ¡ claramente definido con `dag_id`, `owner`, `start_date`, `schedule_interval`, `catchup`.
- âœ… Tareas son reutilizables o composables (no megatareas).
- âœ… Dependencias explÃ­citas (no hay caminos ocultos de datos).
- âœ… DAG es stateless entre ejecuciones (idempotencia).
- âŒ Evita DAGs dinÃ¡micos sin control de nombre.

**Operadores y Tareas:**
- âœ… Operador elegido es el correcto segÃºn caso (HttpSensor/SimpleHttpOperator para APIs, SparkSubmitOperator para Spark, S3Operator para uploads).
- âœ… Tareas definen claros `upstream` y `downstream`.
- âœ… Timeouts y `execution_timeout` estÃ¡n configurados.
- âœ… `task_id` es descriptivo y Ãºnico.
- âŒ Evita BashOperator con comandos complejos; usa Python si es posible.

**Paso de Datos (XCom):**
- âœ… XCom se usa para pequeÃ±os datos (paths, IDs, counts) no binarios.
- âœ… Nombres de XCom son descriptivos (`xcom_pull(task_ids='extract', key='file_path')`).
- âœ… S3 o volumes for big data (DataFrames, archivos); XCom solo para metadata.
- âŒ No uses XCom para pasar DataFrames; es ineficiente.

**Retries y Alertas:**
- âœ… `retries` y `retry_delay` definidos segÃºn SLA (crÃ­tico: 3-5 retries; no crÃ­tico: 1-2).
- âœ… `pool` y `pool_slots` para limitar paralelismo (evita sobrecargar recursos).
- âœ… `sla` definido (ej: `sla=timedelta(hours=2)`); alertas configuradas.
- âœ… `on_failure_callback` y `on_retry_callback` para notificaciones.
- âŒ No dejes retries infinitos o sin delays.

**ConfiguraciÃ³n y Secretos:**
- âœ… Credentials vienen de `Variable` o `Connection` (no hardcoded).
- âœ… IAM roles / permisos mÃ­nimos (least privilege).
- âœ… Secretos en AWS Secrets Manager / Azure KeyVault; Airflow los extrae.
- âœ… Environment variables o conn strings via `conn_id` y Airflow connections.
- âŒ Nunca hardcodees credenciales en DAGs.

**Testing y ValidaciÃ³n:**
- âœ… DAG pasa validaciÃ³n: `airflow dags validate`.
- âœ… Cada tarea tiene condiciones de Ã©xito explÃ­citas (no falla silenciosamente).
- âœ… Logs son estructurados (incluyen `run_id`, `task_id`, `try_number`).
- âœ… DAG tiene tests unitarios para transformaciones lÃ³gicas (si aplica).
- âŒ DAG no debe fallar con errores cryptic.

**Observabilidad:**
- âœ… Cada tarea loguea entrada/salida con contexto.
- âœ… MÃ©tricas expuestas (duration, rows procesadas, errores).
- âœ… IntegraciÃ³n con CloudWatch (AWS) o Application Insights (Azure).
- âœ… Alertas en Slack, PagerDuty u otro si incidentes.
- âŒ No dejes DAGs con logs vacÃ­os.

---

## SECUENCIA DE REVISIÃ“N

1. **Estructura general:**
   - Â¿DAG estÃ¡ bien inicializado? Â¿Tiene owner, schedule_interval, catchup?
   - Â¿Hay dependencias circulares?

2. **Tareas individuales:**
   - Â¿Operador es correcto?
   - Â¿ParÃ¡metros (timeout, retry, pool) estÃ¡n ajustados?
   - Â¿Artefactos/outputs se guardan correctamente?

3. **Flujo de datos:**
   - Â¿XCom se usa solo para metadata?
   - Â¿Big data va a S3/ADLS, no a XCom?
   - Â¿Dependencias son explÃ­citas?

4. **Error handling:**
   - Â¿Retries estÃ¡n configurados?
   - Â¿SLAs definidos?
   - Â¿Callbacks para fallos/alertas?

5. **Seguridad y configuraciÃ³n:**
   - Â¿Credenciales vienen de Variables/Connections?
   - Â¿No hay hardcoding de secrets?
   - Â¿IAM/roles son least privilege?

6. **Observabilidad:**
   - Â¿Logs tienen contexto?
   - Â¿MÃ©tricas expuestas?
   - Â¿Alertas configuradas?

---

## OUTPUT

- Lista de issues prioritizados (crÃ­tico / mayor / menor).
- Ejemplos concretos de cÃ³digo para arreglo.
- Referencias a secciones en instrucciones si aplica.
- RecomendaciÃ³n: "Aprobado para productivo", "Cambios menores" o "Requiere rediseÃ±o".

---

---

## Operadores y LibrerÃ­as Custom Recomendadas

Al revisar DAGs, considera usar operadores pre-construidos de Pragma:

### ðŸ“¦ ciencia-datos-datos-lib-py-operators

**Link:** https://github.com/carlosguzmanbaq/ciencia-datos-datos-lib-py-operators

âœ… **Usar S3MultipartCopyOperator en lugar de BashOperator + aws s3 cp**
```python
# âŒ MEJOR NO:
copy = BashOperator(
    task_id='copy',
    bash_command='aws s3 cp s3://src/large.parquet s3://dst/large.parquet --region us-east-1',
)

# âœ… MEJOR SÃ:
copy = S3MultipartCopyOperator(
    task_id='copy',
    source_s3_key='s3://src/large.parquet',
    destination_s3_key='s3://dst/large.parquet',
    multipart_threshold=5 * 1024**3,  # Auto-multipart para >5GB
)
```

âœ… **Usar FileFerryOperator para S3â†”SFTP**
```python
# FileFerry maneja retry, batch orchestration, session management automÃ¡ticamente
transfer = FileFerryOperator(
    task_id='to_sftp',
    operation='upload',
    source_s3_path='s3://bucket/data/',
    target_sftp_path='/vendor/data/',
)
```

### REFERENCIAS RELACIONADAS

- **Instrucciones:** `instructions_or_rules/data-engineering/modular/02-guidelines.md` (SecciÃ³n 2.2 Pipeline Design, 2.6 Error Handling)
- **Resource:** `resources/data-engineering/airflow-best-practices.md` (Patrones, configuraciÃ³n, patterns reusables)
- **Instrucciones:** `instructions_or_rules/data-engineering/modular/03-technology.md` (Stack recomendado)
- **Instrucciones:** `instructions_or_rules/data-engineering/modular/05-airflow.md` (MWAA, despliegue, operaciones)
- **ðŸ”— Externos:** `ciencia-datos-datos-lib-py-operators`, `ciencia-datos-datos-lib-py-fileferry`
