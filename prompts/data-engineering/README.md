# Data Engineering - Prompts

Prompts reutilizables para tareas comunes de ingenierÃ­a de datos, organizados por nivel de complejidad.

---

## ğŸ¯ Tier 1: Fundamentals
**Aprende:** Principios bÃ¡sicos de validaciÃ³n y calidad de datos.

### ğŸ“‹ Disponibles (Tier 1)

### [data-pipeline-validation.md](./data-pipeline-validation.md)
**PropÃ³sito:** Validar pipelines contra reglas crÃ­ticas: idempotencia, contratos de datos, observabilidad.

**Usa cuando:**
- Necesitas feedback en cÃ³digo de Spark/Flink/dbt antes de deploy
- Quieres verificar que el pipeline es idempotente
- Buscas confirmar que hay contratos de datos bien definidos

**Ejemplo de uso en Copilot:**
```
/data-pipeline-validation

Revisa mi job de Glue. El cÃ³digo estÃ¡ aquÃ­: [pegar cÃ³digo]
Â¿Es idempotente? Â¿Tiene observabilidad estructurada?
```

---

### [data-quality-review.md](./data-quality-review.md)
**PropÃ³sito:** Revisar cobertura de validaciones de datos, expectations, y DQ gates.

**Usa cuando:**
- EstÃ¡s configurando Great Expectations o Deequ
- Necesitas asegurar que tus data quality gates son suficientes
- Quieres validar edge cases (nulls, encoding, distributions)

**Ejemplo de uso en Copilot:**
```
/data-quality-review

AquÃ­ estÃ¡n mis expectations de GE. Â¿Cubro todos los edge cases?
Â¿Puedo tener anomalÃ­as sin que fallen mis checks?
```

---

---

## âš¡ Tier 2: Advanced
**Aprende:** Performance, incidents, y optimizaciones avanzadas.

### [performance-optimization.md](./performance-optimization.md)
**PropÃ³sito:** Analizar y optimizar performance en pipelines. Identifica skew, particionado, query plans.

**Usa cuando:**
- Tu job Spark estÃ¡ lento o usa demasiados recursos
- Necesitas diagnosticar cuello de botella (CPU, I/O, memory spill)
- Quieres propuestas de optimizaciÃ³n con impacto estimado

**Ejemplo de uso en Copilot:**
```
/performance-optimization

Mi job tarda 4 horas hoy vs 30 min hace una semana.
Datos crecieron de 100GB a 500GB. Â¿CÃ³mo optimizo?
```

---

### [incident-triage.md](./incident-triage.md)
**PropÃ³sito:** Diagnosticar y mitigar incidentes: datos faltantes, schema drift, degradaciÃ³n.

**Usa cuando:**
- Un pipeline explotÃ³ en producciÃ³n
- Necesitas respuesta rÃ¡pida (on-call)
- Seguir checklist estructurada vs improvisar

**Ejemplo de uso en Copilot:**
```
/incident-triage

Pipeline de ventas no entregÃ³ datos hoy. 
Ãšltima ejecuciÃ³n fue ayer a las 3 AM.
Sintoniza un plan de acciÃ³n ahora.
```

---

### [airflow-dag-design.md](./airflow-dag-design.md)
**PropÃ³sito:** Validar DAGs de Airflow: estructura, operadores, XCom, retries, seguridad, observabilidad.

**Usa cuando:**
- DiseÃ±as o revisas un DAG antes de deploy
- Necesitas mejorar idempotencia o error handling
- Quieres validar configuraciÃ³n de retries, SLAs y alertas

**Ejemplo de uso en Copilot:**
```
/airflow-dag-design

Tengo este DAG en Airflow. Â¿EstÃ¡ listo para producciÃ³n?
Â¿Hay problemas con XCom o retries?
```

---

### [glue-job-validation.md](./glue-job-validation.md)
**PropÃ³sito:** Validar AWS Glue jobs con configuraciÃ³n declarativa (YAML-based): estructura ETL, transformaciones, manejo de errores, reutilizaciÃ³n.

**Usa cuando:**
- DiseÃ±as o revisas un Glue job antes de deploy
- Necesitas validar que es config-driven (no hardcoded)
- Quieres asegurar que se puede reutilizar para otras tablas
- Validas transformaciones (flatten, type casting, null handling)

**Contenido:**
- Reglas para jobs dinÃ¡micos (YAML-based configuration)
- Patrones Extract, Transform, Load (ETL)
- ValidaciÃ³n de schema, transformaciones, manejo de errores
- Checklist: from declarativa config â†’ reutilizable

**Ejemplo de uso en Copilot:**
```
/glue-job-validation

Revisa mi job de Glue para procesar tablas DynamoDB.
Â¿Es reutilizable para otras tablas? Â¿CÃ³mo agrego nueva tabla sin cÃ³digo?
```

---

## ğŸš€ Tier 3: Specialized
**Aprende:** DiseÃ±o de contracts, decisiones de arquitectura, automatizaciÃ³n.

### [data-contract-design.md](./data-contract-design.md)
**PropÃ³sito:** DiseÃ±ar data contracts completos desde cero, con schemas, SLAs, versionado y gobernanza.

**Usa cuando:**
- Necesitas crear un contrato para un nuevo dataset/tabla
- Quieres mejorar contracts existentes con SLAs/versionado
- EstÃ¡s onboarding un nuevo equipo a data contracts
- Pre-launch validation para nuevos productos de datos

**Contenido:**
- 6 pasos estructurados: descubrimiento â†’ schema â†’ SLA â†’ versioning â†’ governance â†’ testing
- Templates YAML completos (simple + complex)
- Ejemplos reales (Ã³rdenes, clientes, transacciones)
- Testing strategy (unit + contract + DQ)

**Ejemplo de uso en Copilot:**
```
/data-contract-design

DiseÃ±a un contrato para mi tabla de transacciones.
Tengo order_id, customer_id, amount, status, created_date.
Necesito 2h de freshness y SLAs claros.
```

**RelaciÃ³n:** Extiende `resources/data-engineering/data-contract-patterns.md` (Tier 1) con metodologÃ­a prÃ¡ctica de diseÃ±o

---

## ğŸ“š RelaciÃ³n General con Otros Recursos

| Necesitas... | Mira... |
|--------------|----------|
| Entender arquitectura (Lambda/Kappa) | `resources/data-engineering/data-architecture-patterns.md` (Tier 1) |
| DiseÃ±ar contracts | `resources/data-engineering/data-contract-patterns.md` (Tier 1) + este prompt (Tier 3) |
| Implementar testing completo | `resources/data-engineering/testing-data-pipelines.md` (Tier 2) |
| Comparar AWS vs Azure | `resources/data-engineering/aws-azure-data-services.md` (Tier 2) |
| Entender streaming vs batch | `resources/data-engineering/streaming-vs-batch.md` (Tier 3) |
| Instrucciones detalladas | `instructions_or_rules/data-engineering/` |

---

## ğŸš€ Quick Start
1. **Principiante:** Lee Tier 1 (validation + quality)
2. **Implementador:** Usa Tier 2 (performance + incidents + testing)
3. **Arquitecto:** Consulta Tier 3 (decisions + design) + chat mode
