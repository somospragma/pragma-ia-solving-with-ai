# Data Engineering - Prompts

Prompts reutilizables para tareas comunes de ingenier√≠a de datos, organizados por nivel de complejidad.

---

## üéØ Tier 1: Fundamentals
**Aprende:** Principios b√°sicos de validaci√≥n y calidad de datos.

### üìã Disponibles (Tier 1)

### [data-pipeline-validation.md](./data-pipeline-validation.md)
**Prop√≥sito:** Validar pipelines contra reglas cr√≠ticas: idempotencia, contratos de datos, observabilidad.

**Usa cuando:**
- Necesitas feedback en c√≥digo de Spark/Flink/dbt antes de deploy
- Quieres verificar que el pipeline es idempotente
- Buscas confirmar que hay contratos de datos bien definidos

**Ejemplo de uso en Copilot:**
```
/data-pipeline-validation

Revisa mi job de Glue. El c√≥digo est√° aqu√≠: [pegar c√≥digo]
¬øEs idempotente? ¬øTiene observabilidad estructurada?
```

---

### [data-quality-review.md](./data-quality-review.md)
**Prop√≥sito:** Revisar cobertura de validaciones de datos, expectations, y DQ gates.

**Usa cuando:**
- Est√°s configurando Great Expectations o Deequ
- Necesitas asegurar que tus data quality gates son suficientes
- Quieres validar edge cases (nulls, encoding, distributions)

**Ejemplo de uso en Copilot:**
```
/data-quality-review

Aqu√≠ est√°n mis expectations de GE. ¬øCubro todos los edge cases?
¬øPuedo tener anomal√≠as sin que fallen mis checks?
```

---

---

## ‚ö° Tier 2: Advanced
**Aprende:** Performance, incidents, y optimizaciones avanzadas.

### [performance-optimization.md](./performance-optimization.md)
**Prop√≥sito:** Analizar y optimizar performance en pipelines. Identifica skew, particionado, query plans.

**Usa cuando:**
- Tu job Spark est√° lento o usa demasiados recursos
- Necesitas diagnosticar cuello de botella (CPU, I/O, memory spill)
- Quieres propuestas de optimizaci√≥n con impacto estimado

**Ejemplo de uso en Copilot:**
```
/performance-optimization

Mi job tarda 4 horas hoy vs 30 min hace una semana.
Datos crecieron de 100GB a 500GB. ¬øC√≥mo optimizo?
```

---

### [incident-triage.md](./incident-triage.md)
**Prop√≥sito:** Diagnosticar y mitigar incidentes: datos faltantes, schema drift, degradaci√≥n.

**Usa cuando:**
- Un pipeline explot√≥ en producci√≥n
- Necesitas respuesta r√°pida (on-call)
- Seguir checklist estructurada vs improvisar

**Ejemplo de uso en Copilot:**
```
/incident-triage

Pipeline de ventas no entreg√≥ datos hoy. 
√öltima ejecuci√≥n fue ayer a las 3 AM.
Sintoniza un plan de acci√≥n ahora.
```

---

### [airflow-dag-design.md](./airflow-dag-design.md)
**Prop√≥sito:** Validar DAGs de Airflow: estructura, operadores, XCom, retries, seguridad, observabilidad.

**Nota especial:** Este prompt es espec√≠fico para Airflow/MWAA. **Para validaci√≥n agn√≥stica de DAGs/Pipelines en m√∫ltiples plataformas (Airflow, Data Factory, Synapse), usa [pipeline-orchestration-design.md](./pipeline-orchestration-design.md).**

**Usa cuando:**
- Dise√±as o revisas un DAG de Airflow antes de deploy
- Necesitas mejorar idempotencia o error handling
- Quieres validar configuraci√≥n de retries, SLAs y alertas
- Tu contexto es AWS Airflow/MWAA

**Ejemplo de uso en Copilot:**
```
/airflow-dag-design

Tengo este DAG en Airflow. ¬øEst√° listo para producci√≥n?
¬øHay problemas con XCom o retries?
```

---

### [pipeline-orchestration-design.md](./pipeline-orchestration-design.md)
**Prop√≥sito:** Validar dise√±o de pipelines de orquestaci√≥n: DAGs (Airflow), Pipelines (Data Factory), Synapse Pipelines. **Agn√≥stico a plataforma.**

**Usa cuando:**
- Necesitas validaci√≥n gen√©rica para m√∫ltiples plataformas (AWS + Azure)
- Tienes Airflow Y Data Factory en tu arquitectura
- Quieres reglas de estructura/confiabilidad/observabilidad aplicables a cualquier orquestador
- No necesitas detalles espec√≠ficos de sintaxis de cada plataforma

**Ejemplo de uso en Copilot:**
```
/pipeline-orchestration-design

Tengo un pipeline en Airflow y otro en Data Factory.
¬øMe puedes validar ambos con los mismos criterios de confiabilidad?
```

**Contenido:** Estructura agn√≥stica + ejemplos espec√≠ficos por plataforma (Airflow, Data Factory, Synapse).

---

### [glue-job-troubleshooting.md](./glue-job-troubleshooting.md)
**Prop√≥sito:** Diagnosticar y resolver problemas operacionales de ETL jobs: timeouts, hangs, OOM, state management (agn√≥stico de plataforma: AWS Glue, Azure Synapse, Data Factory).

**Usa cuando:**
- ETL job est√° "colgado" en ejecuci√≥n pero logs muestran que fall√≥ (state discrepancy)
- Job es lento (duraci√≥n aument√≥ 4x) sin errores visibles
- Hay OOM (Out of Memory) o task timeouts
- Output tiene duplicados (state management/checkpoint issues)
- Necesitas diagn√≥stico estructurado sin entrar en comandos espec√≠ficos de plataforma

**Ejemplo de uso en Copilot:**
```
/glue-job-troubleshooting

Mi job de Glue/Synapse lleva 2 horas en RUNNING, pero logs muestran que fall√≥ hace 1 hora.
No veo error claro. ¬øQu√© est√° pasando?
```

**Nota:** Agn√≥stico a plataforma. Incluye ejemplos de AWS Glue, Azure Synapse Spark, y Azure Data Factory para patrones equivalentes.

---

### [glue-job-validation.md](./glue-job-validation.md)

**Usa cuando:**
- Dise√±as o revisas un Glue job antes de deploy
- Necesitas validar que es config-driven (no hardcoded)
- Quieres asegurar que se puede reutilizar para otras tablas
- Validas transformaciones (flatten, type casting, null handling)

**Contenido:**
- Reglas para jobs din√°micos (YAML-based configuration)
- Patrones Extract, Transform, Load (ETL)
- Validaci√≥n de schema, transformaciones, manejo de errores
- Checklist: from declarativa config ‚Üí reutilizable

**Ejemplo de uso en Copilot:**
```
/glue-job-validation

Revisa mi job de Glue para procesar tablas DynamoDB.
¬øEs reutilizable para otras tablas? ¬øC√≥mo agrego nueva tabla sin c√≥digo?
```

---

## üöÄ Tier 3: Specialized
**Aprende:** Dise√±o de contracts, decisiones de arquitectura, automatizaci√≥n.

### [data-contract-design.md](./data-contract-design.md)
**Prop√≥sito:** Dise√±ar data contracts completos desde cero, con schemas, SLAs, versionado y gobernanza.

**Usa cuando:**
- Necesitas crear un contrato para un nuevo dataset/tabla
- Quieres mejorar contracts existentes con SLAs/versionado
- Est√°s onboarding un nuevo equipo a data contracts
- Pre-launch validation para nuevos productos de datos

**Contenido:**
- 6 pasos estructurados: descubrimiento ‚Üí schema ‚Üí SLA ‚Üí versioning ‚Üí governance ‚Üí testing
- Templates YAML completos (simple + complex)
- Ejemplos reales (√≥rdenes, clientes, transacciones)
- Testing strategy (unit + contract + DQ)

**Ejemplo de uso en Copilot:**
```
/data-contract-design

Dise√±a un contrato para mi tabla de transacciones.
Tengo order_id, customer_id, amount, status, created_date.
Necesito 2h de freshness y SLAs claros.
```

**Relaci√≥n:** Extiende `resources/data-engineering/data-contract-patterns.md` (Tier 1) con metodolog√≠a pr√°ctica de dise√±o

---

## üìö Relaci√≥n General con Otros Recursos

| Necesitas... | Mira... |
|--------------|----------|
| Entender arquitectura (Lambda/Kappa) | `resources/data-engineering/data-architecture-patterns.md` (Tier 1) |
| Dise√±ar contracts | `resources/data-engineering/data-contract-patterns.md` (Tier 1) + este prompt (Tier 3) |
| Implementar testing completo | `resources/data-engineering/testing-data-pipelines.md` (Tier 2) |
| Comparar AWS vs Azure | `resources/data-engineering/aws-azure-data-services.md` (Tier 2) |
| Entender streaming vs batch | `resources/data-engineering/streaming-vs-batch.md` (Tier 3) |
| Instrucciones detalladas | `instructions_or_rules/data-engineering/` |

---

## üöÄ Quick Start
1. **Principiante:** Lee Tier 1 (validation + quality)
2. **Implementador:** Usa Tier 2 (performance + incidents + testing)
3. **Arquitecto:** Consulta Tier 3 (decisions + design) + chat mode
